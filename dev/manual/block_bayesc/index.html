<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Block BayesC · JWAS.jl</title><meta name="title" content="Block BayesC · JWAS.jl"/><meta property="og:title" content="Block BayesC · JWAS.jl"/><meta property="twitter:title" content="Block BayesC · JWAS.jl"/><meta name="description" content="Documentation for JWAS.jl."/><meta property="og:description" content="Documentation for JWAS.jl."/><meta property="twitter:description" content="Documentation for JWAS.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="JWAS.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">JWAS.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../theory/theory/">Some Theory</a></li><li><a class="tocitem" href="../../citing/citing/">Citing</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../getstarted/">Get Started</a></li><li><a class="tocitem" href="../workflow/">Workflow</a></li><li class="is-active"><a class="tocitem" href>Block BayesC</a><ul class="internal"><li><a class="tocitem" href="#When-This-Path-Is-Used"><span>When This Path Is Used</span></a></li><li><a class="tocitem" href="#Single-Trait-BayesC-Without-Blocks"><span>Single-Trait BayesC Without Blocks</span></a></li><li><a class="tocitem" href="#Single-Trait-Block-BayesC-in-JWAS"><span>Single-Trait Block BayesC in JWAS</span></a></li><li><a class="tocitem" href="#Algorithm-Comparison"><span>Algorithm Comparison</span></a></li><li><a class="tocitem" href="#Computational-Complexity"><span>Computational Complexity</span></a></li><li><a class="tocitem" href="#Detailed-Resource-Model-(Current-fast_blocks-Path)"><span>Detailed Resource Model (Current <code>fast_blocks</code> Path)</span></a></li><li><a class="tocitem" href="#Worked-Large-Scale-Example-(N500,000,-P2,000,000)"><span>Worked Large-Scale Example (<code>N=500,000</code>, <code>P=2,000,000</code>)</span></a></li><li><a class="tocitem" href="#What-To-Watch-Closely"><span>What To Watch Closely</span></a></li><li><a class="tocitem" href="#Example:-Speed/Memory-Tradeoff"><span>Example: Speed/Memory Tradeoff</span></a></li><li><a class="tocitem" href="#Practical-Guidance"><span>Practical Guidance</span></a></li></ul></li><li><a class="tocitem" href="../memory_usage/">Memory Usage</a></li><li><a class="tocitem" href="../streaming_genotype_walkthrough/">Streaming Genotype Walkthrough</a></li><li><a class="tocitem" href="../public/">Public</a></li><li><a class="tocitem" href="../internals/">Internals</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/examples/">Examples</a></li></ul></li><li><a class="tocitem" href="../../FrequentlyAskedQuestions/FrequentlyAskedQuestions/">Frequently Asked Questions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Block BayesC</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Block BayesC</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/reworkhow/JWAS.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/reworkhow/JWAS.jl/blob/master/docs/src/manual/block_bayesc.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Block-BayesC-(fast_blocks)"><a class="docs-heading-anchor" href="#Block-BayesC-(fast_blocks)">Block BayesC (<code>fast_blocks</code>)</a><a id="Block-BayesC-(fast_blocks)-1"></a><a class="docs-heading-anchor-permalink" href="#Block-BayesC-(fast_blocks)" title="Permalink"></a></h1><p>This page explains how JWAS implements block updates for BayesC marker sampling and how the block path changes speed and memory usage. The block BayesC implementation uses a strategy similar to the blocked update scheme described in the BayesR3 paper. For detailed non-block vs block memory accounting, see <a href="../memory_usage/">Memory Usage</a>.</p><p>BayesR3 paper (Methods): https://www.nature.com/articles/s42003-022-03624-1</p><h2 id="When-This-Path-Is-Used"><a class="docs-heading-anchor" href="#When-This-Path-Is-Used">When This Path Is Used</a><a id="When-This-Path-Is-Used-1"></a><a class="docs-heading-anchor-permalink" href="#When-This-Path-Is-Used" title="Permalink"></a></h2><p>Block updates are enabled with:</p><pre><code class="language-julia hljs">out = runMCMC(model, phenotypes; fast_blocks=true)
# or provide a fixed block size
out = runMCMC(model, phenotypes; fast_blocks=64)</code></pre><ul><li>If <code>fast_blocks=true</code>, JWAS chooses <code>block_size = floor(sqrt(nObs))</code>.</li><li>In single-trait BayesA/B/C, JWAS calls <code>BayesABC_block!</code>.</li><li>In multi-trait BayesA/B/C with unconstrained marker covariance (<code>Mi.G.constraint == false</code>), JWAS calls <code>MTBayesABC_block!</code>.</li><li>If <code>Mi.G.constraint == true</code>, JWAS uses <code>megaBayesABC!</code> (non-block path).</li><li>In current multi-trait block mode, the update is sampler-I style (trait-wise <code>δ</code> updates from <code>BigPi[d0]</code>/<code>BigPi[d1]</code>) rather than the non-block sampler-I/II dispatcher.</li><li>Current implementation note in source: this option is intended for one genotype category.</li><li>In current implementation, numeric <code>fast_blocks</code> should satisfy <code>block_size &lt; nMarkers</code> (chain-length scaling indexes the second block start).</li></ul><h2 id="Single-Trait-BayesC-Without-Blocks"><a class="docs-heading-anchor" href="#Single-Trait-BayesC-Without-Blocks">Single-Trait BayesC Without Blocks</a><a id="Single-Trait-BayesC-Without-Blocks-1"></a><a class="docs-heading-anchor-permalink" href="#Single-Trait-BayesC-Without-Blocks" title="Permalink"></a></h2><p>In the standard BayesC update (<code>BayesABC!</code>), each marker <code>j</code> is updated one-by-one:</p><ol><li>Compute conditional posterior terms (<code>rhs</code>, <code>lhs</code>, <code>gHat</code>) from current <code>yCorr</code>.</li><li>Compute marker inclusion probability <code>probDelta1</code>.</li><li>Sample <code>δ[j]</code> (include/exclude) and sample/update <code>β[j]</code>, <code>α[j]</code>.</li><li>Immediately update <code>yCorr</code> using marker column <code>x_j</code>.</li></ol><p>So <code>yCorr</code> is updated every marker.</p><h2 id="Single-Trait-Block-BayesC-in-JWAS"><a class="docs-heading-anchor" href="#Single-Trait-Block-BayesC-in-JWAS">Single-Trait Block BayesC in JWAS</a><a id="Single-Trait-Block-BayesC-in-JWAS-1"></a><a class="docs-heading-anchor-permalink" href="#Single-Trait-Block-BayesC-in-JWAS" title="Permalink"></a></h2><p>In the block version (<code>BayesABC_block!</code>), markers are partitioned into blocks.</p><h3 id="Precomputation-(once-before-MCMC)"><a class="docs-heading-anchor" href="#Precomputation-(once-before-MCMC)">Precomputation (once before MCMC)</a><a id="Precomputation-(once-before-MCMC)-1"></a><a class="docs-heading-anchor-permalink" href="#Precomputation-(once-before-MCMC)" title="Permalink"></a></h3><p>For each block <code>b</code>, JWAS builds:</p><ul><li><code>X_b</code> (block genotype matrix)</li><li><code>X_b&#39;R^{-1}X_b</code> (<code>XpRinvX</code>, block Gram matrix)</li></ul><p><code>X_b&#39;R^{-1}</code> is not persisted as a block matrix. Instead, JWAS computes <code>X_b&#39;R^{-1}yCorr</code> on demand into a reusable block workspace vector each outer iteration.</p><h3 id="Update-flow-inside-each-MCMC-outer-iteration"><a class="docs-heading-anchor" href="#Update-flow-inside-each-MCMC-outer-iteration">Update flow inside each MCMC outer iteration</a><a id="Update-flow-inside-each-MCMC-outer-iteration-1"></a><a class="docs-heading-anchor-permalink" href="#Update-flow-inside-each-MCMC-outer-iteration" title="Permalink"></a></h3><p>For each block:</p><ol><li>Build block RHS once: <code>XpRinvycorr = X_b&#39;R^{-1} yCorr</code>.</li><li>Update markers inside the block using BayesC logic.</li><li>Instead of touching full <code>yCorr</code> each marker, update the block RHS using columns of <code>X_b&#39;R^{-1}X_b</code>.</li><li>After finishing the block, update full <code>yCorr</code> once: <code>yCorr += X_b * (α_old_block - α_new_block)</code>.</li></ol><h3 id="Important-implementation-detail"><a class="docs-heading-anchor" href="#Important-implementation-detail">Important implementation detail</a><a id="Important-implementation-detail-1"></a><a class="docs-heading-anchor-permalink" href="#Important-implementation-detail" title="Permalink"></a></h3><p>In the current JWAS code:</p><ul><li>inner repeats are set to <code>nreps = block_size</code>;</li><li>outer <code>chain_length</code> is reduced by approximately <code>block_size</code>.</li></ul><p>This keeps effective marker-update work on a similar scale while moving much of the per-marker work from <code>nObs</code>-length operations to <code>block_size</code>-length operations.</p><h3 id="Detailed-Comparison-with-BayesR3"><a class="docs-heading-anchor" href="#Detailed-Comparison-with-BayesR3">Detailed Comparison with BayesR3</a><a id="Detailed-Comparison-with-BayesR3-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Comparison-with-BayesR3" title="Permalink"></a></h3><p>Reference paper: BayesR3 (Communications Biology, 2022), DOI: <code>10.1038/s42003-022-03624-1</code>.</p><p>JWAS uses BayesC (not BayesR), but the block linear-algebra strategy closely follows the same blocked Gibbs pattern.</p><h4 id="Step-by-step-correspondence"><a class="docs-heading-anchor" href="#Step-by-step-correspondence">Step-by-step correspondence</a><a id="Step-by-step-correspondence-1"></a><a class="docs-heading-anchor-permalink" href="#Step-by-step-correspondence" title="Permalink"></a></h4><table><tr><th style="text-align: right">BayesR3 paper step</th><th style="text-align: right">JWAS block BayesC implementation</th><th style="text-align: right">Status</th></tr><tr><td style="text-align: right">Partition markers into blocks</td><td style="text-align: right"><code>fast_blocks</code> builds marker blocks</td><td style="text-align: right">Same strategy</td></tr><tr><td style="text-align: right">Build per-block RHS (r<em>b = V</em>b&#39;We)</td><td style="text-align: right"><code>block_rhs!(XpRinvycorr, XArray[i], yCorr, Rinv, unit_weights)</code></td><td style="text-align: right">Same strategy</td></tr><tr><td style="text-align: right">Within-block marker update uses current block RHS</td><td style="text-align: right">BayesC per-marker <code>rhs/lhs/gHat</code> from <code>XpRinvycorr</code></td><td style="text-align: right">Same strategy</td></tr><tr><td style="text-align: right">In-block RHS correction via block Gram column</td><td style="text-align: right"><code>BLAS.axpy!(..., view(XpRinvX[i],:,j), XpRinvycorr)</code></td><td style="text-align: right">Same strategy</td></tr><tr><td style="text-align: right">Update residual once on block exit</td><td style="text-align: right"><code>yCorr += X_b*(α_old_block-α_new_block)</code></td><td style="text-align: right">Same strategy</td></tr></table><h4 id="What-is-different"><a class="docs-heading-anchor" href="#What-is-different">What is different</a><a id="What-is-different-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-different" title="Permalink"></a></h4><table><tr><th style="text-align: right">Topic</th><th style="text-align: right">BayesR3 paper</th><th style="text-align: right">JWAS block BayesC</th><th style="text-align: right">Practical implication</th></tr><tr><td style="text-align: right">Marker prior model</td><td style="text-align: right">BayesR mixture (multiple non-zero normal components plus zero component)</td><td style="text-align: right">BayesC spike-slab style inclusion (<code>δ∈{0,1}</code> for this path)</td><td style="text-align: right">Same acceleration idea, different posterior model</td></tr><tr><td style="text-align: right">Marker state sampling</td><td style="text-align: right">Multi-class mixture state</td><td style="text-align: right">Binary include/exclude state</td><td style="text-align: right">Not numerically identical to BayesR</td></tr><tr><td style="text-align: right">Inner-repeat schedule</td><td style="text-align: right">Uses nominal block size as fixed repeat count across blocks</td><td style="text-align: right"><code>nreps = current block_size</code></td><td style="text-align: right">Last short block may receive fewer inner repeats</td></tr><tr><td style="text-align: right">Outer-loop scheduling</td><td style="text-align: right">Described as a fixed block sweep schedule</td><td style="text-align: right">JWAS also rescales outer <code>chain_length</code> by block size</td><td style="text-align: right">Compare effective updates, not just outer iterations</td></tr><tr><td style="text-align: right">Scope</td><td style="text-align: right">BayesR algorithm</td><td style="text-align: right">JWAS block path is wired to BayesA/B/C marker samplers, with multi-trait block updates implemented in sampler-I style</td><td style="text-align: right">Strategy reused in a different Bayesian alphabet member</td></tr></table><h4 id="Scheduling-detail-(explicit)"><a class="docs-heading-anchor" href="#Scheduling-detail-(explicit)">Scheduling detail (explicit)</a><a id="Scheduling-detail-(explicit)-1"></a><a class="docs-heading-anchor-permalink" href="#Scheduling-detail-(explicit)" title="Permalink"></a></h4><p>JWAS sets <code>nreps</code> equal to the current block size.</p><ul><li>Full blocks: <code>nreps</code> equals the nominal block size.</li><li>Final short block: <code>nreps</code> is smaller than full blocks.</li></ul><p>In the BayesR3 description, <code>nreps</code> is treated as fixed by the nominal block size for all blocks, including the final short block.</p><p>This difference changes the number of within-block Gibbs sweeps for short blocks, but not the core residual/RHS block-update identity.</p><h2 id="Algorithm-Comparison"><a class="docs-heading-anchor" href="#Algorithm-Comparison">Algorithm Comparison</a><a id="Algorithm-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm-Comparison" title="Permalink"></a></h2><table><tr><th style="text-align: right">Aspect</th><th style="text-align: right">Standard BayesC (<code>BayesABC!</code>)</th><th style="text-align: right">Block BayesC (<code>BayesABC_block!</code>)</th><th style="text-align: right">Practical effect</th></tr><tr><td style="text-align: right">Update unit</td><td style="text-align: right">One marker at a time</td><td style="text-align: right">One block, then markers inside block</td><td style="text-align: right">Better cache locality in block path</td></tr><tr><td style="text-align: right"><code>yCorr</code> updates</td><td style="text-align: right">Every marker</td><td style="text-align: right">Once per block</td><td style="text-align: right">Fewer full-length vector updates</td></tr><tr><td style="text-align: right">Main per-marker linear algebra size</td><td style="text-align: right"><code>nObs</code></td><td style="text-align: right"><code>block_size</code> (inside block cache)</td><td style="text-align: right">Lower per-marker arithmetic cost</td></tr><tr><td style="text-align: right">Extra precompute</td><td style="text-align: right">Minimal</td><td style="text-align: right"><code>X_b&#39;R^{-1}X_b</code> for all blocks (RHS computed on demand)</td><td style="text-align: right">More startup work</td></tr><tr><td style="text-align: right">Extra memory</td><td style="text-align: right">Minimal</td><td style="text-align: right">Stores block Gram matrices (<code>XpRinvX</code>) and block workspaces</td><td style="text-align: right">Higher memory than non-block, lower than older persisted-<code>XRinvArray</code> design</td></tr><tr><td style="text-align: right">Chain behavior in current implementation</td><td style="text-align: right">Direct <code>chain_length</code></td><td style="text-align: right">Inner repeats + outer chain scaling</td><td style="text-align: right">Compare runs by effective updates, not only outer iterations</td></tr></table><h2 id="Computational-Complexity"><a class="docs-heading-anchor" href="#Computational-Complexity">Computational Complexity</a><a id="Computational-Complexity-1"></a><a class="docs-heading-anchor-permalink" href="#Computational-Complexity" title="Permalink"></a></h2><p>Use the notation:</p><ul><li><code>N</code>: number of records (<code>nObs</code>)</li><li><code>P</code>: number of markers (<code>nMarkers</code>)</li><li><code>b</code>: nominal block size</li><li><code>B = ceil(P/b)</code>: number of blocks</li><li><code>L</code>: standard (non-block) chain length</li></ul><h3 id="Standard-BayesC-(non-block)"><a class="docs-heading-anchor" href="#Standard-BayesC-(non-block)">Standard BayesC (non-block)</a><a id="Standard-BayesC-(non-block)-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-BayesC-(non-block)" title="Permalink"></a></h3><ul><li>Per MCMC iteration: <code>O(PN)</code> (marker-wise dot products and residual updates over <code>N</code> records)</li><li>Total over <code>L</code> iterations: <code>O(LPN)</code></li></ul><h3 id="JWAS-block-BayesC-(current-implementation)"><a class="docs-heading-anchor" href="#JWAS-block-BayesC-(current-implementation)">JWAS block BayesC (current implementation)</a><a id="JWAS-block-BayesC-(current-implementation)-1"></a><a class="docs-heading-anchor-permalink" href="#JWAS-block-BayesC-(current-implementation)" title="Permalink"></a></h3><p>Let block sizes be <code>s_i</code> with <code>sum_i s_i = P</code>.</p><p>Per outer iteration:</p><ul><li>Block RHS construction across all blocks: <code>O(NP)</code></li><li>In-block updates: <code>O(sum_i s_i^3)</code> (because <code>nreps = s_i</code> and in-block RHS updates are length-<code>s_i</code>)</li><li>Residual updates on block exit across all blocks: <code>O(NP)</code></li></ul><p>So per outer iteration:</p><ul><li><code>O(NP + sum_i s_i^3)</code></li><li>With near-uniform blocks (<code>s_i ≈ b</code>): <code>O(NP + P b^2)</code></li></ul><p>JWAS rescales outer iterations to approximately <code>m = floor(L/b)</code>, so the main total cost is:</p><ul><li><code>O((L/b) * (NP + P b^2)) = O(LP(N/b + b))</code></li></ul><h3 id="BayesR3-(block-strategy-and-paper-fit)"><a class="docs-heading-anchor" href="#BayesR3-(block-strategy-and-paper-fit)">BayesR3 (block strategy and paper fit)</a><a id="BayesR3-(block-strategy-and-paper-fit)-1"></a><a class="docs-heading-anchor-permalink" href="#BayesR3-(block-strategy-and-paper-fit)" title="Permalink"></a></h3><p>BayesR3 uses the same blocked-update strategy family (block RHS, in-block updates using a block Gram matrix, then a block-exit residual update), but it is a BayesR mixture model rather than BayesC. This changes constants (more mixture-state work per marker), not the core block linear-algebra pattern.</p><p><strong>Operation-count view (dense blocked implementation):</strong></p><ul><li>BayesR3 runs a <em>nominal</em> number of inner cycles <code>n</code> per block, and the paper recommends <code>n</code> be equal to the (nominal) block size <code>b</code>.</li><li>With <code>n = b</code>, the leading operation-count terms match the same block strategy family as JWAS: total work scales like <code>O(LP(N/b + b))</code>.</li></ul><p><strong>Paper runtime fit (Fig. 5):</strong></p><ul><li>The BayesR3 paper reports an empirical timing model where processing time per SNP is proportional to <code>(N + b)/b = N/b + 1</code>.</li><li>This is a fit to measured runtime for their implementation/hardware and is not a formal asymptotic operation-count derivation. It effectively treats the in-block work (the <code>+b</code>-type term) as a small constant relative to the <code>N/b</code> term in that regime.</li></ul><h3 id="Practical-differences-in-complexity-interpretation"><a class="docs-heading-anchor" href="#Practical-differences-in-complexity-interpretation">Practical differences in complexity interpretation</a><a id="Practical-differences-in-complexity-interpretation-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-differences-in-complexity-interpretation" title="Permalink"></a></h3><ul><li>JWAS and BayesR3 share the same blocked-update strategy family, but are not identical in constants/scheduling details.</li><li>JWAS uses <code>nreps = current block_size</code> for each block (including the final short block).</li><li>BayesR3 describes using the nominal block repeat count for all blocks, including the final short block.</li></ul><h3 id="Numerical-example-(N200,000,-P2,000,000)"><a class="docs-heading-anchor" href="#Numerical-example-(N200,000,-P2,000,000)">Numerical example (<code>N=200,000</code>, <code>P=2,000,000</code>)</a><a id="Numerical-example-(N200,000,-P2,000,000)-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-example-(N200,000,-P2,000,000)" title="Permalink"></a></h3><p>Assume <code>fast_blocks=true</code>, so JWAS uses <code>b = floor(sqrt(N)) = 447</code>. Then:</p><ul><li><code>B = ceil(P/b) = ceil(2,000,000/447) = 4,475</code> blocks</li><li>Standard BayesC total scaling: <code>O(LPN) = O(L * 2,000,000 * 200,000)</code></li><li>JWAS block BayesC main scaling: <code>O(LP(N/b + b)) = O(L * 2,000,000 * (200,000/447 + 447))</code></li><li>BayesR3 paper timing fit: runtime per SNP <code>∝ (N + b)/b</code>, so total runtime <code>∝ L * 2,000,000 * (200,000/447 + 1)</code></li></ul><p>So the per-<code>LP</code> coefficients are:</p><ul><li>Standard BayesC: <code>200,000</code></li><li>JWAS block BayesC operation-count: <code>~894.4</code> (from <code>N/b + b</code>)</li><li>BayesR3 paper fit: <code>~448.4</code> (from <code>N/b + 1</code>)</li></ul><p>This implies:</p><ul><li>JWAS block vs standard: <code>~224x</code> lower</li><li>BayesR3 paper fit vs standard: <code>~446x</code> lower</li><li>The apparent <code>~2.0x</code> gap between <code>~894</code> and <code>~448</code> is not an apples-to-apples complexity comparison: it is the difference between an operation-count model (<code>N/b + b</code>) and an empirical runtime fit (<code>N/b + 1</code>).</li></ul><h2 id="Detailed-Resource-Model-(Current-fast_blocks-Path)"><a class="docs-heading-anchor" href="#Detailed-Resource-Model-(Current-fast_blocks-Path)">Detailed Resource Model (Current <code>fast_blocks</code> Path)</a><a id="Detailed-Resource-Model-(Current-fast_blocks-Path)-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Resource-Model-(Current-fast_blocks-Path)" title="Permalink"></a></h2><p>Use:</p><ul><li><code>N</code>: records</li><li><code>P</code>: markers</li><li><code>b</code>: nominal block size</li><li><code>s_i</code>: size of block <code>i</code>, <code>sum_i s_i = P</code></li><li><code>t</code>: bytes per floating-point value (<code>4</code> for <code>Float32</code>, <code>8</code> for <code>Float64</code>)</li></ul><h3 id="Memory-formulas"><a class="docs-heading-anchor" href="#Memory-formulas">Memory formulas</a><a id="Memory-formulas-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-formulas" title="Permalink"></a></h3><p>Current block implementation (after removing persistent <code>XRinvArray</code>) stores:</p><ul><li>dense <code>X</code>: <code>N*P</code> values</li><li>block Gram matrices <code>XpRinvX</code>: <code>sum_i s_i^2</code> values</li><li>marker summary <code>xpRinvx</code>: <code>P</code> values</li><li>optional <code>xRinvArray</code> extra <code>N*P</code> only for non-unit weights in the non-block marker path</li><li>small reusable block workspaces (<code>O(b)</code>) for RHS and local deltas</li></ul><p>Approximate totals:</p><ul><li>Unit weights:<ul><li><code>Mem_block_unit ~= t * (N*P + sum_i s_i^2 + P) + O(b*t)</code></li></ul></li><li>Non-unit weights:<ul><li><code>Mem_block_nonunit ~= t * (2*N*P + sum_i s_i^2 + P) + O(b*t)</code></li></ul></li></ul><h3 id="Runtime-working-set"><a class="docs-heading-anchor" href="#Runtime-working-set">Runtime working set</a><a id="Runtime-working-set-1"></a><a class="docs-heading-anchor-permalink" href="#Runtime-working-set" title="Permalink"></a></h3><p>Per block update, active high-volume buffers are:</p><ul><li><code>X_b</code> view (<code>N x s_i</code>; no data copy)</li><li><code>XpRinvX[i]</code> (<code>s_i x s_i</code>)</li><li>block RHS workspace (<code>s_i</code>)</li><li><code>yCorr</code> (<code>N</code>)</li></ul><p>So peak additional block-local workspace is roughly:</p><ul><li><code>O(s_i^2 + s_i + N)</code> values</li></ul><h3 id="I/O-and-precompute-considerations"><a class="docs-heading-anchor" href="#I/O-and-precompute-considerations">I/O and precompute considerations</a><a id="I/O-and-precompute-considerations-1"></a><a class="docs-heading-anchor-permalink" href="#I/O-and-precompute-considerations" title="Permalink"></a></h3><p>For in-memory dense <code>X</code>, no out-of-core read is required during MCMC sweeps. The expensive setup term is building <code>XpRinvX</code>:</p><ul><li>precompute cost scales with approximately <code>O(N * sum_i s_i^2)</code> (<code>~O(NPb)</code> under near-uniform blocks)</li></ul><p>This setup can dominate startup time for very large <code>N,P</code>, even when per-iteration sampling is fast.</p><h2 id="Worked-Large-Scale-Example-(N500,000,-P2,000,000)"><a class="docs-heading-anchor" href="#Worked-Large-Scale-Example-(N500,000,-P2,000,000)">Worked Large-Scale Example (<code>N=500,000</code>, <code>P=2,000,000</code>)</a><a id="Worked-Large-Scale-Example-(N500,000,-P2,000,000)-1"></a><a class="docs-heading-anchor-permalink" href="#Worked-Large-Scale-Example-(N500,000,-P2,000,000)" title="Permalink"></a></h2><p>Assume <code>fast_blocks=true</code>, so <code>b=floor(sqrt(N))=707</code>.</p><ul><li><code>B = ceil(P/b) = 2,829</code></li><li><code>sum_i s_i^2 = 1,413,937,788</code></li></ul><p>Memory-relevant terms:</p><table><tr><th style="text-align: right">Term</th><th style="text-align: right">Float32</th><th style="text-align: right">Float64</th></tr><tr><td style="text-align: right"><code>X</code></td><td style="text-align: right"><code>~4.00 TB</code> (<code>3.64 TiB</code>)</td><td style="text-align: right"><code>~8.00 TB</code> (<code>7.28 TiB</code>)</td></tr><tr><td style="text-align: right"><code>XpRinvX</code></td><td style="text-align: right"><code>~5.66 GB</code> (<code>5.27 GiB</code>)</td><td style="text-align: right"><code>~11.31 GB</code> (<code>10.53 GiB</code>)</td></tr><tr><td style="text-align: right"><code>xpRinvx</code></td><td style="text-align: right"><code>~8.0 MB</code></td><td style="text-align: right"><code>~16.0 MB</code></td></tr></table><p>So for unit weights, block mode remains dominated by <code>X</code>, with <code>XpRinvX</code> as the main incremental memory term.</p><h2 id="What-To-Watch-Closely"><a class="docs-heading-anchor" href="#What-To-Watch-Closely">What To Watch Closely</a><a id="What-To-Watch-Closely-1"></a><a class="docs-heading-anchor-permalink" href="#What-To-Watch-Closely" title="Permalink"></a></h2><ol><li><code>block_size</code> choice:<ul><li>too small: less speedup (<code>N/b</code> term remains large)</li><li>too large: <code>XpRinvX</code> memory and precompute cost rise (<code>~P*b</code> memory and <code>~NPb</code> setup trend)</li></ul></li><li>Effective chain length:<ul><li>current implementation rescales outer iterations and uses inner repeats (<code>nreps = block_size</code>)</li><li>compare runs by effective updates, not only outer-iteration count</li></ul></li><li>Final short block behavior:<ul><li>last block uses smaller <code>nreps</code> (equal to its own size), so sweep symmetry differs slightly</li></ul></li><li>Multi-trait block path specifics:<ul><li>current path is sampler-I style for unconstrained covariance mode</li><li>extra temporaries (e.g., trait-wise old-alpha handling) can become noticeable at larger trait counts</li></ul></li><li>Numerical reproducibility:<ul><li>mathematically equivalent refactors (e.g., in-place BLAS updates) can change floating-point roundoff</li><li>expect tiny non-bitwise differences, especially in <code>Float32</code></li></ul></li><li>Weighting mode:<ul><li>block <code>XRinvArray</code> is no longer persisted</li><li>separate non-unit weighted non-block <code>xRinvArray</code> materialization remains a distinct issue</li></ul></li><li>Scope constraints:<ul><li>current source notes this fast block option is intended for one genotype category</li><li>numeric <code>fast_blocks</code> should keep <code>block_size &lt; nMarkers</code></li></ul></li></ol><h2 id="Example:-Speed/Memory-Tradeoff"><a class="docs-heading-anchor" href="#Example:-Speed/Memory-Tradeoff">Example: Speed/Memory Tradeoff</a><a id="Example:-Speed/Memory-Tradeoff-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Speed/Memory-Tradeoff" title="Permalink"></a></h2><p>Assume:</p><ul><li><code>nObs = 5_000</code></li><li><code>nMarkers = 50_000</code></li><li><code>block_size = 70</code> (similar to <code>sqrt(nObs)</code>)</li><li><code>nBlocks = 715</code></li></ul><p>Approximate memory (Float32):</p><table><tr><th style="text-align: right">Item</th><th style="text-align: right">Approx size</th></tr><tr><td style="text-align: right">Genotype matrix <code>X</code> (<code>nObs x nMarkers</code>)</td><td style="text-align: right"><code>~953.7 MiB</code></td></tr><tr><td style="text-align: right">Extra <code>XpRinvX</code> in block mode</td><td style="text-align: right"><code>~13.4 MiB</code></td></tr></table><p>Interpretation:</p><ul><li>Block mode can be much faster for large <code>nObs</code>, because heavy per-marker operations are shifted to block-level cached operations.</li><li>Block mode uses more memory than non-block mode, mainly from <code>XpRinvX</code> (plus small block workspaces).</li><li>Practical speedup is typically below theoretical arithmetic speedup due to random branching, allocation overhead, and BLAS/runtime effects.</li></ul><h2 id="Practical-Guidance"><a class="docs-heading-anchor" href="#Practical-Guidance">Practical Guidance</a><a id="Practical-Guidance-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-Guidance" title="Permalink"></a></h2><ol><li>Start with <code>fast_blocks=true</code> for large marker sets and enough RAM.</li><li>If memory is tight, set a smaller numeric block size (e.g., <code>32</code> or <code>64</code>) and benchmark.</li><li>If speed gain is small, try a few block sizes and choose based on wall time + memory headroom.</li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../workflow/">« Workflow</a><a class="docs-footer-nextpage" href="../memory_usage/">Memory Usage »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Thursday 26 February 2026 22:07">Thursday 26 February 2026</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
