<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Handling Large Genotype Data Without Loading the Full Matrix into Memory · JWAS.jl</title><meta name="title" content="Handling Large Genotype Data Without Loading the Full Matrix into Memory · JWAS.jl"/><meta property="og:title" content="Handling Large Genotype Data Without Loading the Full Matrix into Memory · JWAS.jl"/><meta property="twitter:title" content="Handling Large Genotype Data Without Loading the Full Matrix into Memory · JWAS.jl"/><meta name="description" content="Documentation for JWAS.jl."/><meta property="og:description" content="Documentation for JWAS.jl."/><meta property="twitter:description" content="Documentation for JWAS.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="JWAS.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">JWAS.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../theory/theory/">Some Theory</a></li><li><a class="tocitem" href="../../citing/citing/">Citing</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../getstarted/">Get Started</a></li><li><a class="tocitem" href="../workflow/">Workflow</a></li><li><a class="tocitem" href="../block_bayesc/">Block BayesC</a></li><li><a class="tocitem" href="../memory_usage/">Memory Usage</a></li><li><a class="tocitem" href="../streaming_genotype_walkthrough/">Streaming Genotype Walkthrough</a></li><li><a class="tocitem" href="../public/">Public</a></li><li><a class="tocitem" href="../internals/">Internals</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/examples/">Examples</a></li></ul></li><li><a class="tocitem" href="../../FrequentlyAskedQuestions/FrequentlyAskedQuestions/">Frequently Asked Questions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Handling Large Genotype Data Without Loading the Full Matrix into Memory</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Handling Large Genotype Data Without Loading the Full Matrix into Memory</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/reworkhow/JWAS.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/reworkhow/JWAS.jl/blob/master/docs/src/manual/large_genotype_data_streaming.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Handling-Large-Genotype-Data-Without-Loading-the-Full-Matrix-into-Memory"><a class="docs-heading-anchor" href="#Handling-Large-Genotype-Data-Without-Loading-the-Full-Matrix-into-Memory">Handling Large Genotype Data Without Loading the Full Matrix into Memory</a><a id="Handling-Large-Genotype-Data-Without-Loading-the-Full-Matrix-into-Memory-1"></a><a class="docs-heading-anchor-permalink" href="#Handling-Large-Genotype-Data-Without-Loading-the-Full-Matrix-into-Memory" title="Permalink"></a></h1><p>This page summarizes scalability limits and representation options for the standard original BayesC path (<code>fast_blocks=false</code>), with focus on very large datasets such as <code>N=500,000</code> individuals and <code>P=2,000,000</code> markers.</p><h2 id="Scope"><a class="docs-heading-anchor" href="#Scope">Scope</a><a id="Scope-1"></a><a class="docs-heading-anchor-permalink" href="#Scope" title="Permalink"></a></h2><ul><li>Model path: standard BayesC, non-block marker updates.</li><li>Objective: understand memory and speed constraints, and compare storage approaches.</li><li>This page does not change BayesC posterior equations; it compares data representation and runtime behavior.</li></ul><h2 id="Current-JWAS-Status"><a class="docs-heading-anchor" href="#Current-JWAS-Status">Current JWAS Status</a><a id="Current-JWAS-Status-1"></a><a class="docs-heading-anchor-permalink" href="#Current-JWAS-Status" title="Permalink"></a></h2><ul><li>Dense loading remains the default and primary path:<ul><li><code>get_genotypes(...; storage=:dense)</code> (default)</li><li>Existing dense workflows are unchanged.</li></ul></li><li>Streaming loading is additive and opt-in:<ul><li><code>get_genotypes(...; storage=:stream)</code></li><li>Status: experimental MVP for large-data BayesC.</li></ul></li><li>Streaming conversion is out-of-core:<ul><li><code>prepare_streaming_genotypes(...)</code> no longer materializes dense <code>N x P</code> in RAM.</li><li>Conversion uses temporary disk plus final packed output (set <code>tmpdir</code> for placement).</li></ul></li></ul><h3 id="Streaming-MVP-workflow"><a class="docs-heading-anchor" href="#Streaming-MVP-workflow">Streaming MVP workflow</a><a id="Streaming-MVP-workflow-1"></a><a class="docs-heading-anchor-permalink" href="#Streaming-MVP-workflow" title="Permalink"></a></h3><pre><code class="language-julia hljs"># 1) one-time conversion to packed backend
prefix = prepare_streaming_genotypes(\&quot;genotypes.csv\&quot;;
                                     separator=&#39;,&#39;,
                                     header=true,
                                     quality_control=true,
                                     center=true,
                                     conversion_mode=:lowmem,
                                     auto_dense_max_bytes=2^30,
                                     tmpdir=nothing,
                                     cleanup_temp=true,
                                     disk_guard_ratio=0.9)

# 2) load packed backend (no dense N x P matrix in memory)
geno = get_genotypes(prefix, 1.0;
                     method=\&quot;BayesC\&quot;,
                     storage=:stream)</code></pre><h3 id="Streaming-MVP-constraints"><a class="docs-heading-anchor" href="#Streaming-MVP-constraints">Streaming MVP constraints</a><a id="Streaming-MVP-constraints-1"></a><a class="docs-heading-anchor-permalink" href="#Streaming-MVP-constraints" title="Permalink"></a></h3><ul><li>single-trait only</li><li>method = <code>BayesC</code> only</li><li><code>fast_blocks=false</code> only</li><li>unit residual weights only</li><li><code>double_precision=false</code> only</li><li>complete genomic data only (no single-step)</li><li>exact genotype/phenotype ID match and order required</li><li><code>outputEBV</code>/<code>output_heritability</code> are disabled in MVP streaming mode</li></ul><h2 id="Notation"><a class="docs-heading-anchor" href="#Notation">Notation</a><a id="Notation-1"></a><a class="docs-heading-anchor-permalink" href="#Notation" title="Permalink"></a></h2><ul><li><code>N</code>: number of records (<code>nObs</code>)</li><li><code>P</code>: number of markers (<code>nMarkers</code>)</li><li><code>t</code>: bytes per stored value (<code>4</code> for <code>Float32</code>, <code>8</code> for <code>Float64</code>)</li><li><code>L</code>: chain length (effective non-block iterations)</li><li><code>c</code>: number of markers decoded/loaded per chunk in an out-of-core path</li><li><code>B_io</code>: effective sustained storage throughput (GB/s)</li></ul><h2 id="Baseline-Complexity-(Original-BayesC)"><a class="docs-heading-anchor" href="#Baseline-Complexity-(Original-BayesC)">Baseline Complexity (Original BayesC)</a><a id="Baseline-Complexity-(Original-BayesC)-1"></a><a class="docs-heading-anchor-permalink" href="#Baseline-Complexity-(Original-BayesC)" title="Permalink"></a></h2><p>For single-trait original BayesC, each MCMC iteration updates markers one-by-one. The dominant per-iteration cost scales as:</p><ul><li><code>O(NP)</code></li></ul><p>Total over <code>L</code> iterations:</p><ul><li><code>O(LNP)</code></li></ul><p>At very large <code>N</code> and <code>P</code>, runtime is dominated by repeated full marker sweeps.</p><h3 id="Rough-operation-count"><a class="docs-heading-anchor" href="#Rough-operation-count">Rough operation count</a><a id="Rough-operation-count-1"></a><a class="docs-heading-anchor-permalink" href="#Rough-operation-count" title="Permalink"></a></h3><p>For each marker update in the single-trait loop:</p><ul><li>one <code>dot(x_j, yCorr)</code> term (<code>~2N</code> floating-point ops),</li><li>one residual update <code>yCorr += (old-new)*x_j</code> (<code>~2N</code> ops),</li><li>small <code>O(1)</code> scalar work.</li></ul><p>A practical back-of-the-envelope is:</p><ul><li>per iteration: <code>~4NP</code> flops</li><li>total: <code>~4LNP</code> flops</li></ul><p>For <code>N=500,000</code>, <code>P=2,000,000</code>:</p><ul><li><code>~4e12</code> flops per iteration (before overhead/branching/cache effects)</li></ul><h2 id="Baseline-Memory-(Original-BayesC)"><a class="docs-heading-anchor" href="#Baseline-Memory-(Original-BayesC)">Baseline Memory (Original BayesC)</a><a id="Baseline-Memory-(Original-BayesC)-1"></a><a class="docs-heading-anchor-permalink" href="#Baseline-Memory-(Original-BayesC)" title="Permalink"></a></h2><p>Main memory terms for one genotype category:</p><ul><li>Dense genotype matrix <code>X</code>: <code>N x P</code></li><li><code>xpRinvx</code>: length <code>P</code></li><li><code>xRinvArray</code>:<ul><li>unit weights: aliases <code>xArray</code> (no extra <code>N x P</code> data copy)</li><li>non-unit weights: extra <code>N x P</code> copy</li></ul></li></ul><p>Approximate totals:</p><ul><li>Unit weights: <code>Mem_nonblock_unit ~= t * (N*P + P)</code></li><li>Non-unit weights: <code>Mem_nonblock_nonunit ~= t * (2*N*P + P)</code></li></ul><p>In practice, <code>N*P</code> dominates.</p><h2 id="Worked-Example-(N500,000,-P2,000,000)"><a class="docs-heading-anchor" href="#Worked-Example-(N500,000,-P2,000,000)">Worked Example (<code>N=500,000</code>, <code>P=2,000,000</code>)</a><a id="Worked-Example-(N500,000,-P2,000,000)-1"></a><a class="docs-heading-anchor-permalink" href="#Worked-Example-(N500,000,-P2,000,000)" title="Permalink"></a></h2><ul><li><code>N*P = 1,000,000,000,000</code></li><li>2-bit packed genotype payload size (for comparison): <code>N*P/4 = 250,000,000,000</code> bytes</li></ul><h3 id="Memory-totals-for-original-BayesC"><a class="docs-heading-anchor" href="#Memory-totals-for-original-BayesC">Memory totals for original BayesC</a><a id="Memory-totals-for-original-BayesC-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-totals-for-original-BayesC" title="Permalink"></a></h3><table><tr><th style="text-align: right">Case</th><th style="text-align: right">Float32</th><th style="text-align: right">Float64</th></tr><tr><td style="text-align: right">Unit weights</td><td style="text-align: right"><code>~4.00 TB</code> (<code>3.64 TiB</code>)</td><td style="text-align: right"><code>~8.00 TB</code> (<code>7.28 TiB</code>)</td></tr><tr><td style="text-align: right">Non-unit weights</td><td style="text-align: right"><code>~8.00 TB</code> (<code>7.28 TiB</code>)</td><td style="text-align: right"><code>~16.00 TB</code> (<code>14.55 TiB</code>)</td></tr></table><h2 id="Out-of-Core-Working-Set-Math-(Original-BayesC)"><a class="docs-heading-anchor" href="#Out-of-Core-Working-Set-Math-(Original-BayesC)">Out-of-Core Working-Set Math (Original BayesC)</a><a id="Out-of-Core-Working-Set-Math-(Original-BayesC)-1"></a><a class="docs-heading-anchor-permalink" href="#Out-of-Core-Working-Set-Math-(Original-BayesC)" title="Permalink"></a></h2><p>If genotypes are streamed by chunks of <code>c</code> markers and decoded into Float32:</p><ul><li>chunk buffer: <code>N*c*4</code> bytes</li><li>marker-state vectors (<code>α</code>, <code>β</code>, <code>δ</code>): <code>O(P)</code> (small relative to chunk for large <code>N</code>)</li><li>response/residual vectors (<code>y</code>, <code>yCorr</code>): <code>O(N)</code> (also small relative to chunk)</li></ul><p>Approximate runtime working set:</p><ul><li><code>Mem_working ~= 4*N*c + O(P) + O(N)</code> bytes</li></ul><p>Example at <code>N=500,000</code>:</p><table><tr><th style="text-align: right">Chunk size <code>c</code></th><th style="text-align: right"><code>X_chunk</code> buffer (Float32)</th></tr><tr><td style="text-align: right">128</td><td style="text-align: right"><code>~256 MB</code></td></tr><tr><td style="text-align: right">256</td><td style="text-align: right"><code>~512 MB</code></td></tr><tr><td style="text-align: right">512</td><td style="text-align: right"><code>~1.02 GB</code></td></tr><tr><td style="text-align: right">1024</td><td style="text-align: right"><code>~2.05 GB</code></td></tr></table><p>This is why out-of-core design can be RAM-feasible even when dense in-memory is not.</p><h2 id="Representation-Approaches-for-Original-BayesC"><a class="docs-heading-anchor" href="#Representation-Approaches-for-Original-BayesC">Representation Approaches for Original BayesC</a><a id="Representation-Approaches-for-Original-BayesC-1"></a><a class="docs-heading-anchor-permalink" href="#Representation-Approaches-for-Original-BayesC" title="Permalink"></a></h2><h3 id="1.-Dense-In-Memory-(current-baseline)"><a class="docs-heading-anchor" href="#1.-Dense-In-Memory-(current-baseline)">1. Dense In-Memory (current baseline)</a><a id="1.-Dense-In-Memory-(current-baseline)-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Dense-In-Memory-(current-baseline)" title="Permalink"></a></h3><ul><li>Store dense <code>X</code> in RAM.</li><li>Best arithmetic locality.</li><li>Requires multi-terabyte RAM at this scale.</li><li>No extra decode overhead.</li></ul><h3 id="2.-Dense-Out-of-Core-(mmap-style-dense-backend)"><a class="docs-heading-anchor" href="#2.-Dense-Out-of-Core-(mmap-style-dense-backend)">2. Dense Out-of-Core (<code>mmap</code>-style dense backend)</a><a id="2.-Dense-Out-of-Core-(mmap-style-dense-backend)-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Dense-Out-of-Core-(mmap-style-dense-backend)" title="Permalink"></a></h3><ul><li>Dense storage on disk, streamed by marker sweep.</li><li>Reduces RAM requirement, but disk remains dense-scale.</li></ul><p>For the example:</p><ul><li>Dense file size (<code>Float32</code>): <code>~4.00 TB</code></li></ul><p>Pros:</p><ul><li>lowest engineering risk</li><li>minimal change to current math path</li></ul><p>Cons:</p><ul><li>very large disk footprint</li><li>heavy I/O per iteration</li><li>usually bottlenecked by storage bandwidth, not compute</li></ul><h3 id="3.-Native-Bit-Packed-Backend-(recommended-long-term)"><a class="docs-heading-anchor" href="#3.-Native-Bit-Packed-Backend-(recommended-long-term)">3. Native Bit-Packed Backend (recommended long-term)</a><a id="3.-Native-Bit-Packed-Backend-(recommended-long-term)-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Native-Bit-Packed-Backend-(recommended-long-term)" title="Permalink"></a></h3><ul><li>Store genotypes in compact 2-bit representation.</li><li>Decode on demand into small work buffers during marker updates.</li></ul><p>For the example:</p><ul><li>Packed payload: <code>~250 GB</code> (plus metadata/index overhead)</li></ul><p>Pros:</p><ul><li>major reduction in disk footprint and read traffic</li><li>scalable foundation for large <code>N, P</code></li><li>can target predictable RAM via chunk size <code>c</code></li></ul><p>Cons:</p><ul><li>higher engineering effort (decoder, metadata, validation)</li><li>decode overhead during runtime</li></ul><h3 id="4.-External-Adapter-Backend-(e.g.,-PLINK-style-reader)"><a class="docs-heading-anchor" href="#4.-External-Adapter-Backend-(e.g.,-PLINK-style-reader)">4. External Adapter Backend (e.g., PLINK-style reader)</a><a id="4.-External-Adapter-Backend-(e.g.,-PLINK-style-reader)-1"></a><a class="docs-heading-anchor-permalink" href="#4.-External-Adapter-Backend-(e.g.,-PLINK-style-reader)" title="Permalink"></a></h3><ul><li>Reuse existing external compact format and stream into BayesC update loops.</li></ul><p>Pros:</p><ul><li>interoperability with existing data pipelines</li></ul><p>Cons:</p><ul><li>parser/dependency complexity</li><li>performance depends on adapter implementation and access pattern</li></ul><h2 id="Fast-Block-Implementation-(fast_blocks)-in-Large-Data-Context"><a class="docs-heading-anchor" href="#Fast-Block-Implementation-(fast_blocks)-in-Large-Data-Context">Fast-Block Implementation (<code>fast_blocks</code>) in Large-Data Context</a><a id="Fast-Block-Implementation-(fast_blocks)-in-Large-Data-Context-1"></a><a class="docs-heading-anchor-permalink" href="#Fast-Block-Implementation-(fast_blocks)-in-Large-Data-Context" title="Permalink"></a></h2><p>Although this page focuses on original BayesC (<code>fast_blocks=false</code>), large-data planning usually compares it to <code>fast_blocks=true</code>.</p><p>Let:</p><ul><li><code>b</code>: nominal block size</li><li><code>s_i</code>: block sizes with <code>sum_i s_i = P</code></li><li><code>S = sum_i s_i^2</code> (near-uniform approximation: <code>S ~ P*b</code>)</li></ul><p>Current block path (after removing persistent <code>XRinvArray</code>) is approximately:</p><ul><li>Unit weights:<ul><li><code>Mem_block_unit ~= t * (N*P + S + P) + O(b*t)</code></li></ul></li><li>Non-unit weights:<ul><li><code>Mem_block_nonunit ~= t * (2*N*P + S + P) + O(b*t)</code></li></ul></li></ul><p>Computation scales approximately as:</p><ul><li>per outer iteration: <code>O(NP + sum_i s_i^3)</code> (<code>~O(NP + P*b^2)</code> for near-uniform blocks)</li><li>with JWAS outer-loop rescaling (<code>m ~ L/b</code>): <code>O(LP(N/b + b))</code></li></ul><p>So <code>fast_blocks</code> can substantially reduce arithmetic relative to original BayesC, while adding mainly the <code>S</code> term for <code>XpRinvX</code>.</p><h2 id="What-To-Watch-for-fast_blocks"><a class="docs-heading-anchor" href="#What-To-Watch-for-fast_blocks">What To Watch for <code>fast_blocks</code></a><a id="What-To-Watch-for-fast_blocks-1"></a><a class="docs-heading-anchor-permalink" href="#What-To-Watch-for-fast_blocks" title="Permalink"></a></h2><ol><li>Block-size tradeoff:<ul><li>smaller <code>b</code>: less memory, weaker speedup</li><li>larger <code>b</code>: higher <code>XpRinvX</code> memory and heavier precompute</li></ul></li><li>Effective iteration accounting:<ul><li>compare runs by effective updates, not only reported outer iterations</li></ul></li><li>Final short block:<ul><li>last block gets fewer inner repeats because <code>nreps = block_size</code> per block</li></ul></li><li>Startup/precompute cost:<ul><li><code>XpRinvX</code> build can dominate startup on very large <code>N,P</code></li></ul></li><li>Multi-trait specifics:<ul><li>current multi-trait block mode behavior differs from the full non-block sampler dispatcher</li></ul></li><li>Numerical reproducibility:<ul><li>equivalent algebraic refactors may change floating-point roundoff (especially <code>Float32</code>)</li></ul></li><li>Weighting caveat:<ul><li>block <code>XRinvArray</code> is no longer persisted, but non-unit weighted non-block <code>xRinvArray</code> remains a separate optimization topic</li></ul></li></ol><h2 id="Speed-and-I/O-Considerations"><a class="docs-heading-anchor" href="#Speed-and-I/O-Considerations">Speed and I/O Considerations</a><a id="Speed-and-I/O-Considerations-1"></a><a class="docs-heading-anchor-permalink" href="#Speed-and-I/O-Considerations" title="Permalink"></a></h2><p>Original BayesC still has <code>O(LNP)</code> compute scaling regardless of representation. Representation changes mostly affect:</p><ul><li>feasible RAM footprint</li><li>disk footprint</li><li>I/O volume per marker sweep</li></ul><p>For out-of-core paths, each iteration needs at least one full marker sweep. Thus, reducing per-sweep data size (e.g., dense vs 2-bit packed) directly reduces I/O pressure.</p><h3 id="I/O-lower-bound-model"><a class="docs-heading-anchor" href="#I/O-lower-bound-model">I/O lower-bound model</a><a id="I/O-lower-bound-model-1"></a><a class="docs-heading-anchor-permalink" href="#I/O-lower-bound-model" title="Permalink"></a></h3><p>Ignoring compute and decode for a lower bound:</p><ul><li><code>T_io_per_iter &gt;= Bytes_per_sweep / B_io</code></li><li><code>T_io_total &gt;= L * Bytes_per_sweep / B_io</code></li></ul><p>For the worked example (<code>Float32</code> dense vs 2-bit packed):</p><ul><li>dense sweep bytes: <code>~4,000 GB</code></li><li>packed sweep bytes: <code>~250 GB</code></li></ul><p>If <code>B_io = 3 GB/s</code>:</p><table><tr><th style="text-align: right">Storage form</th><th style="text-align: right">I/O lower bound per iteration</th></tr><tr><td style="text-align: right">Dense Float32</td><td style="text-align: right"><code>~22.2 min</code></td></tr><tr><td style="text-align: right">2-bit packed</td><td style="text-align: right"><code>~1.39 min</code></td></tr></table><p>At <code>L=1000</code> iterations (I/O lower bound only):</p><table><tr><th style="text-align: right">Storage form</th><th style="text-align: right">I/O lower bound total</th></tr><tr><td style="text-align: right">Dense Float32</td><td style="text-align: right"><code>~15.4 days</code></td></tr><tr><td style="text-align: right">2-bit packed</td><td style="text-align: right"><code>~23.1 hours</code></td></tr></table><p>These are lower bounds; actual wall time is higher once decode and BayesC compute are included.</p><h2 id="Side-by-Side-Summary"><a class="docs-heading-anchor" href="#Side-by-Side-Summary">Side-by-Side Summary</a><a id="Side-by-Side-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Side-by-Side-Summary" title="Permalink"></a></h2><table><tr><th style="text-align: right">Approach</th><th style="text-align: right">RAM feasibility at 500k x 2M</th><th style="text-align: right">Disk footprint</th><th style="text-align: right">I/O pressure</th><th style="text-align: right">Engineering effort</th></tr><tr><td style="text-align: right">Dense in-memory</td><td style="text-align: right">very poor</td><td style="text-align: right">low (if already in RAM source)</td><td style="text-align: right">low</td><td style="text-align: right">low</td></tr><tr><td style="text-align: right">Dense out-of-core (<code>mmap</code>)</td><td style="text-align: right">good</td><td style="text-align: right">very high (<code>~4 TB</code>, Float32)</td><td style="text-align: right">very high</td><td style="text-align: right">low</td></tr><tr><td style="text-align: right">Native 2-bit packed</td><td style="text-align: right">good</td><td style="text-align: right">moderate (<code>~250 GB</code> payload)</td><td style="text-align: right">much lower</td><td style="text-align: right">high</td></tr><tr><td style="text-align: right">External compact adapter</td><td style="text-align: right">good</td><td style="text-align: right">format-dependent (often compact)</td><td style="text-align: right">lower than dense</td><td style="text-align: right">medium-high</td></tr></table><h2 id="Validation-Details-Needed-for-Large-Data-Streaming"><a class="docs-heading-anchor" href="#Validation-Details-Needed-for-Large-Data-Streaming">Validation Details Needed for Large-Data Streaming</a><a id="Validation-Details-Needed-for-Large-Data-Streaming-1"></a><a class="docs-heading-anchor-permalink" href="#Validation-Details-Needed-for-Large-Data-Streaming" title="Permalink"></a></h2><p>For any out-of-core backend, validate:</p><ol><li>numerical equivalence vs dense baseline on small/medium data (<code>α</code>, <code>δ</code>, <code>yCorr</code> traces),</li><li>missing/imputation and centering consistency,</li><li>deterministic behavior with fixed RNG seed,</li><li>chunk-size invariance (same results for different <code>c</code> within FP tolerance),</li><li>sustained throughput and memory caps under long chains.</li></ol><h2 id="Practical-Takeaways"><a class="docs-heading-anchor" href="#Practical-Takeaways">Practical Takeaways</a><a id="Practical-Takeaways-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-Takeaways" title="Permalink"></a></h2><ol><li>At <code>N=500k, P=2M</code>, original BayesC dense in RAM is not practical on typical hardware.</li><li>Out-of-core dense storage improves RAM feasibility but remains very heavy in disk/I/O.</li><li>A compact backend (native bit-packed or external compact format) is the practical direction for large-scale original BayesC.</li><li>Even with compact storage, runtime remains fundamentally <code>O(LNP)</code>; representation helps feasibility, not asymptotic compute.</li></ol></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Thursday 26 February 2026 22:07">Thursday 26 February 2026</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
